{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download NLTK all modules - search in stackoverflow for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venkata_kalluri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tex=\"Hello this is a test word. this is test line. Donald Trump is US President. Modi bans black money.\"\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# break into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello this is a test word.',\n",
       " 'this is test line.',\n",
       " 'Donald Trump is US President.',\n",
       " 'Modi bans black money.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=sent_tokenize(tex)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'this', 'is', 'a', 'test', 'word', '.'],\n",
       " ['this', 'is', 'test', 'line', '.'],\n",
       " ['Donald', 'Trump', 'is', 'US', 'President', '.'],\n",
       " ['Modi', 'bans', 'black', 'money', '.']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[word_tokenize(sent) for sent in sents]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'this', 'is', 'a', 'test', 'word', '.', 'this', 'is', 'test', 'line', '.', 'Donald', 'Trump', 'is', 'US', 'President', '.', 'Modi', 'bans', 'black', 'money', '.']\n"
     ]
    }
   ],
   "source": [
    "print word_tokenize(tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meaningless words aka stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'a',\n",
       " u'about',\n",
       " u'above',\n",
       " u'after',\n",
       " u'again',\n",
       " u'against',\n",
       " u'ain',\n",
       " u'all',\n",
       " u'am',\n",
       " u'an',\n",
       " u'and',\n",
       " u'any',\n",
       " u'are',\n",
       " u'aren',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'because',\n",
       " u'been',\n",
       " u'before',\n",
       " u'being',\n",
       " u'below',\n",
       " u'between',\n",
       " u'both',\n",
       " u'but',\n",
       " u'by',\n",
       " u'can',\n",
       " u'couldn',\n",
       " u'd',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'do',\n",
       " u'does',\n",
       " u'doesn',\n",
       " u'doing',\n",
       " u'don',\n",
       " u'down',\n",
       " u'during',\n",
       " u'each',\n",
       " u'few',\n",
       " u'for',\n",
       " u'from',\n",
       " u'further',\n",
       " u'had',\n",
       " u'hadn',\n",
       " u'has',\n",
       " u'hasn',\n",
       " u'have',\n",
       " u'haven',\n",
       " u'having',\n",
       " u'he',\n",
       " u'her',\n",
       " u'here',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'him',\n",
       " u'himself',\n",
       " u'his',\n",
       " u'how',\n",
       " u'i',\n",
       " u'if',\n",
       " u'in',\n",
       " u'into',\n",
       " u'is',\n",
       " u'isn',\n",
       " u'it',\n",
       " u'its',\n",
       " u'itself',\n",
       " u'just',\n",
       " u'll',\n",
       " u'm',\n",
       " u'ma',\n",
       " u'me',\n",
       " u'mightn',\n",
       " u'more',\n",
       " u'most',\n",
       " u'mustn',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'needn',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'now',\n",
       " u'o',\n",
       " u'of',\n",
       " u'off',\n",
       " u'on',\n",
       " u'once',\n",
       " u'only',\n",
       " u'or',\n",
       " u'other',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'out',\n",
       " u'over',\n",
       " u'own',\n",
       " u're',\n",
       " u's',\n",
       " u'same',\n",
       " u'shan',\n",
       " u'she',\n",
       " u'should',\n",
       " u'shouldn',\n",
       " u'so',\n",
       " u'some',\n",
       " u'such',\n",
       " u't',\n",
       " u'than',\n",
       " u'that',\n",
       " u'the',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'them',\n",
       " u'themselves',\n",
       " u'then',\n",
       " u'there',\n",
       " u'these',\n",
       " u'they',\n",
       " u'this',\n",
       " u'those',\n",
       " u'through',\n",
       " u'to',\n",
       " u'too',\n",
       " u'under',\n",
       " u'until',\n",
       " u'up',\n",
       " u've',\n",
       " u'very',\n",
       " u'was',\n",
       " u'wasn',\n",
       " u'we',\n",
       " u'were',\n",
       " u'weren',\n",
       " u'what',\n",
       " u'when',\n",
       " u'where',\n",
       " u'which',\n",
       " u'while',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'why',\n",
       " u'will',\n",
       " u'with',\n",
       " u'won',\n",
       " u'wouldn',\n",
       " u'y',\n",
       " u'you',\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# punctutation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "custStopWords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "for word in word_tokenize(tex):\n",
    "    if word in custStopWords:\n",
    "        continue;\n",
    "    else:\n",
    "        wordlist.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'test',\n",
       " 'word',\n",
       " 'test',\n",
       " 'line',\n",
       " 'Donald',\n",
       " 'Trump',\n",
       " 'US',\n",
       " 'President',\n",
       " 'Modi',\n",
       " 'bans',\n",
       " 'black',\n",
       " 'money']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Donald', 'Trump'), 1),\n",
       " (('Hello', 'test'), 1),\n",
       " (('Modi', 'bans'), 1),\n",
       " (('President', 'Modi'), 1),\n",
       " (('Trump', 'US'), 1),\n",
       " (('US', 'President'), 1),\n",
       " (('bans', 'black'), 1),\n",
       " (('black', 'money'), 1),\n",
       " (('line', 'Donald'), 1),\n",
       " (('test', 'line'), 1),\n",
       " (('test', 'word'), 1),\n",
       " (('word', 'test'), 1)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "finder=BigramCollocationFinder.from_words(wordlist)\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text2='hi buy buying brought eat eating ate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem the words that means remove suffixs and make those words same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'buy', 'buy', 'brought', 'eat', 'eat', 'at']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer as ls\n",
    "stemList=[]\n",
    "for word in word_tokenize(text2):\n",
    "    stemList.append(ls().stem(word))\n",
    "    \n",
    "print(stemList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find vocubulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'NN'),\n",
       " ('buy', 'VB'),\n",
       " ('buying', 'VBG'),\n",
       " ('brought', 'JJ'),\n",
       " ('eat', 'NN'),\n",
       " ('eating', 'VBG'),\n",
       " ('ate', 'NN')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find tresures of the given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('ring.n.01'), u'a characteristic sound')\n",
      "(Synset('ring.n.02'), u'a toroidal shape')\n",
      "(Synset('hoop.n.02'), u'a rigid circular band of metal or wood or other material used for holding or fastening or hanging or pulling')\n",
      "(Synset('closed_chain.n.01'), u'(chemistry) a chain of atoms in a molecule that forms a closed loop')\n",
      "(Synset('gang.n.01'), u'an association of criminals')\n",
      "(Synset('ring.n.06'), u'the sound of a bell ringing')\n",
      "(Synset('ring.n.07'), u'a platform usually marked off by ropes in which contestants box or wrestle')\n",
      "(Synset('ring.n.08'), u'jewelry consisting of a circlet of precious metal (often set with jewels) worn on the finger')\n",
      "(Synset('band.n.12'), u'a strip of material attached to the leg of a bird to identify it (as in studies of bird migration)')\n",
      "(Synset('ring.v.01'), u'sound loudly and sonorously')\n",
      "(Synset('resound.v.01'), u'ring or echo with sound')\n",
      "(Synset('ring.v.03'), u'make (bells) ring, often for the purposes of musical edification')\n",
      "(Synset('call.v.03'), u'get or try to get into communication (with someone) by telephone')\n",
      "(Synset('surround.v.01'), u'extend on all sides of simultaneously; encircle')\n",
      "(Synset('ring.v.06'), u'attach a ring to the foot of, in order to identify')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for word in wn.synsets('ring'):\n",
    "    print(word,word.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the context of word in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('ring.n.06'), u'the sound of a bell ringing')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "mean=lesk(word_tokenize('ring the bell and go out of school'),'ring')\n",
    "print(mean,mean.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Synset('ring.v.06'), u'attach a ring to the foot of, in order to identify')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "mean=lesk(word_tokenize('your node ring are good'),'ring')\n",
    "print(mean,mean.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
